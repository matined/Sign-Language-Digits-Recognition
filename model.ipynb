{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.layers as tfl\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "\n",
    "\n",
    "import utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-31 23:30:56.878739: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2022-01-31 23:30:56.878991: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-01-31 23:30:56.880095: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    }
   ],
   "source": [
    "data = utils.get_data()\n",
    "X_train = tf.cast(data['X_train'], dtype=tf.float32)\n",
    "y_train = tf.cast(data['y_train'], dtype=tf.float32)\n",
    "X_test = tf.cast(data['X_test'], dtype=tf.float32)\n",
    "y_test = tf.cast(data['y_test'], dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NN Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tfl.ZeroPadding2D(padding=1, input_shape=(100, 100, 3)),\n",
    "\n",
    "    tfl.Conv2D(50, 7, strides=1),\n",
    "    tfl.BatchNormalization(axis=3),\n",
    "    tfl.ReLU(),\n",
    "\n",
    "    tfl.MaxPool2D(),\n",
    "\n",
    "    tfl.Conv2D(100, 7, strides=1),\n",
    "    tfl.BatchNormalization(axis=3),\n",
    "    tfl.ReLU(),\n",
    "\n",
    "    tfl.MaxPool2D(),\n",
    "    \n",
    "    tfl.Conv2D(200, 5, strides=1),\n",
    "    tfl.BatchNormalization(axis=3),\n",
    "    tfl.ReLU(),\n",
    "\n",
    "    tfl.MaxPool2D(),\n",
    "    tfl.Flatten(),\n",
    "    tfl.Dense(10, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "zero_padding2d (ZeroPadding2 (None, 102, 102, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 96, 96, 50)        7400      \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 96, 96, 50)        200       \n",
      "_________________________________________________________________\n",
      "re_lu (ReLU)                 (None, 96, 96, 50)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 48, 48, 50)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 42, 42, 100)       245100    \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 42, 42, 100)       400       \n",
      "_________________________________________________________________\n",
      "re_lu_1 (ReLU)               (None, 42, 42, 100)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 21, 21, 100)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 17, 17, 200)       500200    \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 17, 17, 200)       800       \n",
      "_________________________________________________________________\n",
      "re_lu_2 (ReLU)               (None, 17, 17, 200)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 8, 8, 200)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 12800)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 10)                128010    \n",
      "=================================================================\n",
      "Total params: 882,110\n",
      "Trainable params: 881,410\n",
      "Non-trainable params: 700\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "54/54 [==============================] - 89s 2s/step - loss: 4.8137 - accuracy: 0.3651\n",
      "Epoch 2/10\n",
      "54/54 [==============================] - 89s 2s/step - loss: 0.6687 - accuracy: 0.7980\n",
      "Epoch 3/10\n",
      "54/54 [==============================] - 90s 2s/step - loss: 0.3110 - accuracy: 0.8924\n",
      "Epoch 4/10\n",
      "54/54 [==============================] - 87s 2s/step - loss: 0.1399 - accuracy: 0.9579\n",
      "Epoch 5/10\n",
      "54/54 [==============================] - 89s 2s/step - loss: 0.1334 - accuracy: 0.9611\n",
      "Epoch 6/10\n",
      "54/54 [==============================] - 89s 2s/step - loss: 0.0862 - accuracy: 0.9728\n",
      "Epoch 7/10\n",
      "54/54 [==============================] - 89s 2s/step - loss: 0.0755 - accuracy: 0.9726\n",
      "Epoch 8/10\n",
      "54/54 [==============================] - 92s 2s/step - loss: 0.0579 - accuracy: 0.9837\n",
      "Epoch 9/10\n",
      "54/54 [==============================] - 91s 2s/step - loss: 0.0108 - accuracy: 0.9988\n",
      "Epoch 10/10\n",
      "54/54 [==============================] - 92s 2s/step - loss: 0.0319 - accuracy: 0.9879\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f542455a5e0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, batch_size=32, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 215ms/step - loss: 0.2524 - accuracy: 0.9000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.25244373083114624, 0.8999999761581421]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-31 22:06:46.015138: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model/assets\n"
     ]
    }
   ],
   "source": [
    "tf.saved_model.save(model, 'model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Failed to import pydot. You must `pip install pydot` and install graphviz (https://graphviz.gitlab.io/download/), ', 'for `pydotprint` to work.')\n"
     ]
    }
   ],
   "source": [
    "tf.keras.utils.plot_model(model, to_file='model_plot.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "08fe9a84316eac9769d7a3f037646143ff09d8a48fdb2e1a2a32cf855c887973"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('sign_lang': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
